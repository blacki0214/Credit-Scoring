{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Ensemble Model on Feature-Engineered Dataset\n",
        "\n",
        "This notebook builds an ensemble model (LightGBM + XGBoost) on the engineered feature set in `data/train_feature_engineered.csv`.\n",
        "It performs stratified cross-validation, blends fold predictions, and persists trained models plus evaluation metadata for downstream use."
      ],
      "id": "intro"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    precision_recall_curve,\n",
        "    f1_score,\n",
        ")\n",
        "\n",
        "import lightgbm as lgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "DATA_PATH = Path('data/train_feature_engineered.csv')\n",
        "OUTPUT_DIR = Path('output/models/advanced')\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n"
      ],
      "id": "imports"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df = pd.read_csv(DATA_PATH)\n",
        "print(f'Dataset shape: {df.shape}')\n",
        "print('Class balance:')\n",
        "print(df['TARGET'].value_counts(normalize=True).rename('share'))\n",
        "df.head()\n"
      ],
      "id": "load-data"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "bool_cols = df.select_dtypes(include='bool').columns\n",
        "if len(bool_cols):\n",
        "    df[bool_cols] = df[bool_cols].astype('uint8')\n",
        "\n",
        "X = df.drop(columns=['TARGET', 'SK_ID_CURR'])\n",
        "y = df['TARGET'].astype(int)\n",
        "\n",
        "float_cols = X.select_dtypes(include=['float64']).columns\n",
        "if len(float_cols):\n",
        "    X[float_cols] = X[float_cols].astype(np.float32)\n",
        "\n",
        "scale_pos_weight = (len(y) - y.sum()) / y.sum()\n",
        "print(f'scale_pos_weight: {scale_pos_weight:.2f}')\n",
        "print(f'Feature matrix: {X.shape[0]} rows x {X.shape[1]} columns')\n"
      ],
      "id": "prep"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def find_best_threshold(y_true, y_score):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
        "    if thresholds.size == 0:\n",
        "        fallback = f1_score(y_true, (y_score >= 0.5).astype(int))\n",
        "        return 0.5, fallback\n",
        "    f1_scores = 2 * precision[:-1] * recall[:-1] / (precision[:-1] + recall[:-1] + 1e-12)\n",
        "    best_idx = int(np.argmax(f1_scores))\n",
        "    return float(thresholds[best_idx]), float(f1_scores[best_idx])\n",
        "\n",
        "lgbm_params = dict(\n",
        "    boosting_type='gbdt',\n",
        "    objective='binary',\n",
        "    learning_rate=0.03,\n",
        "    n_estimators=2000,\n",
        "    num_leaves=96,\n",
        "    max_depth=-1,\n",
        "    subsample=0.85,\n",
        "    subsample_freq=1,\n",
        "    colsample_bytree=0.65,\n",
        "    reg_alpha=0.15,\n",
        "    reg_lambda=1.2,\n",
        "    min_child_samples=40,\n",
        "    min_split_gain=0.01,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        ")\n",
        "\n",
        "xgb_params = dict(\n",
        "    objective='binary:logistic',\n",
        "    learning_rate=0.02,\n",
        "    n_estimators=2500,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.6,\n",
        "    reg_alpha=0.2,\n",
        "    reg_lambda=1.0,\n",
        "    min_child_weight=5,\n",
        "    gamma=0.2,\n",
        "    eval_metric='auc',\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    tree_method='hist',\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
      ],
      "id": "config"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "oof_preds = {\n",
        "    'lgbm': np.zeros(len(X), dtype=np.float32),\n",
        "    'xgb': np.zeros(len(X), dtype=np.float32),\n",
        "}\n",
        "fold_metrics = []\n",
        "lgb_best_iterations = []\n",
        "xgb_best_iterations = []\n",
        "feature_importances = []\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y), start=1):\n",
        "    print(f'Fold {fold}')\n",
        "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
        "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
        "\n",
        "    lgb_model = lgb.LGBMClassifier(**lgbm_params)\n",
        "    lgb_model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        eval_metric='auc',\n",
        "        callbacks=[lgb.early_stopping(150), lgb.log_evaluation(period=0)],\n",
        "    )\n",
        "    best_iter = lgb_model.best_iteration_ or lgbm_params['n_estimators']\n",
        "    lgb_best_iterations.append(int(best_iter))\n",
        "    preds_lgb = lgb_model.predict_proba(X_valid)[:, 1]\n",
        "    oof_preds['lgbm'][valid_idx] = preds_lgb\n",
        "\n",
        "    feature_importances.append(\n",
        "        pd.DataFrame({\n",
        "            'feature': X.columns,\n",
        "            'importance': lgb_model.booster_.feature_importance(importance_type='gain'),\n",
        "            'fold': fold,\n",
        "        })\n",
        "    )\n",
        "\n",
        "    xgb_model = XGBClassifier(**xgb_params)\n",
        "    xgb_model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        early_stopping_rounds=200,\n",
        "        verbose=False,\n",
        "    )\n",
        "    best_iter_xgb = getattr(xgb_model, 'best_iteration', None)\n",
        "    if best_iter_xgb is None:\n",
        "        best_iter_xgb = getattr(xgb_model, 'best_iteration_', xgb_params['n_estimators'])\n",
        "    else:\n",
        "        best_iter_xgb = int(best_iter_xgb) + 1\n",
        "    xgb_best_iterations.append(int(best_iter_xgb))\n",
        "    preds_xgb = xgb_model.predict_proba(X_valid)[:, 1]\n",
        "    oof_preds['xgb'][valid_idx] = preds_xgb\n",
        "\n",
        "    blended = 0.6 * preds_lgb + 0.4 * preds_xgb\n",
        "    roc_auc = roc_auc_score(y_valid, blended)\n",
        "    ap = average_precision_score(y_valid, blended)\n",
        "    best_threshold, best_f1 = find_best_threshold(y_valid, blended)\n",
        "\n",
        "    fold_metrics.append({\n",
        "        'fold': fold,\n",
        "        'roc_auc': roc_auc,\n",
        "        'average_precision': ap,\n",
        "        'best_threshold': best_threshold,\n",
        "        'best_f1': best_f1,\n",
        "        'lgb_best_iteration': int(best_iter),\n",
        "        'xgb_best_iteration': int(best_iter_xgb),\n",
        "    })\n",
        "\n",
        "fold_metrics_df = pd.DataFrame(fold_metrics)\n",
        "fold_metrics_df\n"
      ],
      "id": "cv"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "blended_oof = 0.6 * oof_preds['lgbm'] + 0.4 * oof_preds['xgb']\n",
        "overall_roc = roc_auc_score(y, blended_oof)\n",
        "overall_ap = average_precision_score(y, blended_oof)\n",
        "best_threshold, best_f1 = find_best_threshold(y, blended_oof)\n",
        "\n",
        "print(f'OOF ROC-AUC: {overall_roc:.4f}')\n",
        "print(f'OOF Average Precision: {overall_ap:.4f}')\n",
        "print(f'Best global threshold: {best_threshold:.3f} -> F1 {best_f1:.4f}')\n",
        "\n",
        "feature_importance_df = (\n",
        "    pd.concat(feature_importances)\n",
        "    .groupby('feature', as_index=False)['importance']\n",
        "    .mean()\n",
        "    .sort_values(by='importance', ascending=False)\n",
        ")\n",
        "feature_importance_df.head(20)\n"
      ],
      "id": "metrics"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "avg_lgb_iter = int(np.round(np.mean(lgb_best_iterations)))\n",
        "avg_xgb_iter = int(np.round(np.mean(xgb_best_iterations)))\n",
        "\n",
        "print(f'Average best iteration -> LightGBM: {avg_lgb_iter}, XGBoost: {avg_xgb_iter}')\n",
        "\n",
        "final_lgbm = lgb.LGBMClassifier(**{**lgbm_params, 'n_estimators': avg_lgb_iter})\n",
        "final_xgb = XGBClassifier(**{**xgb_params, 'n_estimators': avg_xgb_iter})\n",
        "\n",
        "final_lgbm.fit(X, y)\n",
        "final_xgb.fit(X, y, verbose=False)\n",
        "\n",
        "joblib.dump(final_lgbm, OUTPUT_DIR / 'lgbm_advanced_model.pkl')\n",
        "joblib.dump(final_xgb, OUTPUT_DIR / 'xgb_advanced_model.pkl')\n",
        "\n",
        "metadata = {\n",
        "    'data_path': str(DATA_PATH.resolve()),\n",
        "    'n_samples': int(X.shape[0]),\n",
        "    'n_features': int(X.shape[1]),\n",
        "    'class_balance': {\n",
        "        'positive': int(y.sum()),\n",
        "        'negative': int((1 - y).sum()),\n",
        "        'positive_rate': float(y.mean()),\n",
        "    },\n",
        "    'scale_pos_weight': float(scale_pos_weight),\n",
        "    'avg_lgb_iterations': avg_lgb_iter,\n",
        "    'avg_xgb_iterations': avg_xgb_iter,\n",
        "    'overall_metrics': {\n",
        "        'roc_auc': float(overall_roc),\n",
        "        'average_precision': float(overall_ap),\n",
        "        'best_threshold': float(best_threshold),\n",
        "        'best_f1': float(best_f1),\n",
        "    },\n",
        "    'cv_metrics': fold_metrics,\n",
        "}\n",
        "\n",
        "with open(OUTPUT_DIR / 'advanced_metadata.json', 'w', encoding='utf-8') as fp:\n",
        "    json.dump(metadata, fp, indent=2)\n",
        "\n",
        "feature_importance_df.to_csv(OUTPUT_DIR / 'lgbm_feature_importance.csv', index=False)\n",
        "fold_metrics_df.to_csv(OUTPUT_DIR / 'cv_metrics.csv', index=False)\n",
        "pd.DataFrame({\n",
        "    'SK_ID_CURR': df['SK_ID_CURR'],\n",
        "    'TARGET': y,\n",
        "    'BLENDED_PROB': blended_oof,\n",
        "}).to_csv(OUTPUT_DIR / 'oof_predictions.csv', index=False)\n",
        "\n",
        "print('Artifacts saved under', OUTPUT_DIR.resolve())\n"
      ],
      "id": "save"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "- Run this notebook to train the ensemble and review the saved metrics under `output/models/advanced`.\n",
        "- If GPU resources are available, set `tree_method='gpu_hist'` for XGBoost to speed up training.\n",
        "- Consider tuning the blend weights or adding calibrated models (e.g., CatBoost) for further lift."
      ],
      "id": "next"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}